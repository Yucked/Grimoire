<p align="center">
	<img src="https://github.com/Yucked/Grimoire/assets/20461656/e31d016b-9a58-4b6d-9b4f-b29458140651" />
	</br>
	<a href="https://discord.gg/ZJaVXK8">
		<img src="https://img.shields.io/badge/Discord-Support-%237289DA.svg?logo=discord&style=for-the-badge&logoWidth=30&labelColor=0d0d0d" />
	</a>
    <a href="#docker">
		<img src="https://img.shields.io/badge/Docker-Supported-%232496ED.svg?logo=docker&style=for-the-badge&logoWidth=30&labelColor=0d0d0d" />
	</a>
    <a href="#docker">
		<img src="https://img.shields.io/badge/Built On-.NET-%23512BD4.svg?logo=dotnet&style=for-the-badge&logoWidth=30&labelColor=0d0d0d" />
	</a> 
	<p align="center">
	     🪭 - Grimoire is self-hosted manga reader & downloader. Supporting multiple scan-sites and aggregating sites.
  </p>
</p>


## `⚔️ Features:`
> For full list of planned features or features in development, please check [issues](https://github.com/Yucked/Grimoire/issues)

- Currently supports saving mangas from sources to database to reduce requests
- Memory cache for quicker access to manga/chapters/images | Can be disabled for direct access
- Supporting multiple sources (more added with time)
- Parallel & Asynchronous for faster parsing and fetching data

## `🐳 Docker:`
- To build it yourself, download `Dockerfile` from [here](https://github.com/Yucked/Grimoire/blob/main/Dockerfile).
- To use pre-built images, download `docker-compose.yml` from [here](https://github.com/Yucked/Grimoire/blob/main/docker-compose.yml) and run `docker compose up -d`.

## `📸 Images:`

![image](https://github.com/Yucked/Grimoire/assets/20461656/793456f6-f632-4c70-b9d7-c08efb0ebe68)

![image](https://github.com/Yucked/Grimoire/assets/20461656/42f78ada-d431-437e-a1da-d4a3f8ea40dc)

![image](https://github.com/Yucked/Grimoire/assets/20461656/64a26e9d-5829-4e0e-92e6-9fe8f1e7cab9)


## `🤔 FAQ:`
- Can I use it? Is it production ready?
> Absolutely YES! Use it at your own risk though.

- Why not some 3rd party pre-existing program that does what your program does already with support for 500 sites?
> L + ratio + too many sites + too slow + doesn't work as expected + can't relate + old UI + be better

- Can you add xyz site please?
> yeah sure, just make sure you give all the necessary information for scraping 😒
